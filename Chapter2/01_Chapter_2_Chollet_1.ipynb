{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Chapter 2, Deep Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple machine learning model to show the big picture and then learn the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# what is the shape of train_images and test_images?\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# what is the length of the train labels and test labels?\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training examples = 60000\n",
      "the number of classes = 10\n",
      "Dimention of images = 60000 x 28  \n",
      "The number of occurances of each class in the dataset = {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}  \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the images\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"the number of training examples = %i\" % train_images.shape[0])\n",
    "print(\"the number of classes = %i\" % len(np.unique(train_labels)))\n",
    "print(\"Dimention of images = {:d} x {:d}  \".format(train_images.shape[0],train_images.shape[1])  )\n",
    "\n",
    "#This line will allow us to know the number of occurrences of each specific class in the data\n",
    "unique, count= np.unique(train_labels, return_counts=True)\n",
    "print(\"The number of occurances of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )\n",
    "\n",
    "# how many images to display (rows*columns)\n",
    "rows = 2\n",
    "columns = 3\n",
    "for index in range(rows*columns):\n",
    "    plt.subplot(rows, columns, index + 1)\n",
    "    plt.imshow(train_images[index], cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.title('label: ' + str(train_labels[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does these values look like? (Nicolas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label= 5 \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Experiment with different indices in the array. Replace \"[0]\" for [89] to take a look to eighty nine index\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[0])\n",
    "print(\"label= %s \" %  train_labels[0])\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "1. Feed the neural network the training data (train_images, train_labels)\n",
    "2. The network will learn to associate images and labels\n",
    "3. Use the test_images to verify if the predictions match the labels from test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three important concepts\n",
    "* Loss function- How the network will measure its performance on the training data\n",
    "* Optimizer- The mechanism through with network will update itself based on the data its been presented and its loss function\n",
    "* Metrics to monitor during training and testing- in this case we will use accuarcy (the fraction of the images that were correctly classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the data into a form the network accepts\n",
    "# transorm the data from an array shape (6000, 28, 28) of type unit8 with values [0,255] to\n",
    "# a float32 array with shape (6000, 28*28) with values between and 1\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorial encode the lables (explained in detail later)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2583 - accuracy: 0.9258\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1047 - accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0677 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0502 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0372 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f901d8b1190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "network.fit(train_images,train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9780\n",
      "test accuracy: 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the test data\n",
    "test_loss,test_acc = network.evaluate(test_images,test_labels)\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "1. Why is the accuracy lower on the test data than the training data?\n",
    "2. Create your own test image of a 4 and an 8 using Microsoft Paint (28,28) pixels and test the images using the model\n",
    "3. Describe your findings and why the model is accurate or not accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a horse or a human.\n",
    "\n",
    "Cambiar la condicion de horse y human para 1,2,3...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(300, 300))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "  else:\n",
    "    print(fn + \" is a horse\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
